application.logging.dir = C:\\Users\\carlo\\Cloudera\\application\\lakeCedacri\\log
application.logging.filename = ${application.logging.dir}\\spark_application.log
application.logging.appender.layout = org.apache.log4j.PatternLayout
application.logging.layout.pattern = %d{yyyy-MM-dd HH:mm:ss} [%p] %C.%M: %m%n

# APPENDERS
# stdout
log4j.appender.stdout = org.apache.log4j.ConsoleAppender
log4j.appender.stdout.Threshold = WARN
log4j.appender.stdout.Target = System.out
log4j.appender.stdout.layout = ${application.logging.appender.layout}
log4j.appender.stdout.layout.ConversionPattern = ${application.logging.layout.pattern}

# rolling_file
log4j.appender.rolling_file = org.apache.log4j.RollingFileAppender
log4j.appender.rolling_file.Threshold = INFO
log4j.appender.rolling_file.append = true
log4j.appender.rolling_file.File = ${application.logging.filename}
log4j.appender.rolling_file.layout = ${application.logging.appender.layout}
log4j.appender.rolling_file.layout.ConversionPattern = ${application.logging.layout.pattern}
log4j.appender.rolling_file.MaxFileSize = 1MB
log4j.appender.rolling_file.MaxBackupIndex = 5

# LOGGERS
log4j.rootLogger = INFO, stdout, rolling_file
log4j.logger.org.apache.hadoop = INFO, stdout, rolling_file
log4j.logger.org.apache.spark = INFO, stdout, rolling_file
log4j.logger.org.spark_project.jetty = WARN, stdout, rolling_file

# avoids Windows-related errors when ShutdownHookManager
# attempts to delete lake_cedacri temporary working directory
log4j.logger.org.apache.spark.util.ShutdownHookManager = OFF
log4j.logger.org.apache.spark.SparkEnv = ERROR

# LOGGER ADDITIVITY
log4j.additivity.org.apache.hadoop = false
log4j.additivity.org.apache.spark = false
log4j.additivity.org.spark_project.jetty = false